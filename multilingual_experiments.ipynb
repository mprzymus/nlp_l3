{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from config import PROBLEM_TEST, CHECKPOINTS_DIR, ENGLISH_TRAIN, ENGLISH_TEST\n",
    "from data import TextDataset, HatefulTweets\n",
    "from functools import partial\n",
    "from nn import train_model, BinaryMLP\n",
    "\n",
    "from experiment import (\n",
    "    run_repeated_labse_single,\n",
    "    run_repeated_labse_multi,\n",
    "    test_inference_time,\n",
    "    calculate_memory_usage,\n",
    "    check_errors,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1\n",
      "Global seed set to 2\n",
      "Global seed set to 3\n",
      "Global seed set to 4\n",
      "Global seed set to 5\n",
      "Global seed set to 6\n",
      "Global seed set to 7\n",
      "Global seed set to 8\n",
      "Global seed set to 9\n",
      "Global seed set to 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test/loss': '0.3486 ± 0.0164',\n",
       " 'test/f1': '0.4444 ± 0.0283',\n",
       " 'test/acc': '0.8822 ± 0.0066',\n",
       " 'test/precision': '0.6048 ± 0.0451',\n",
       " 'test/recall': '0.3515 ± 0.0218',\n",
       " 'train/loss': '0.1310 ± 0.0354',\n",
       " 'train/f1': '0.9113 ± 0.0285',\n",
       " 'train/acc': '0.9845 ± 0.0053',\n",
       " 'train/precision': '0.8894 ± 0.0444',\n",
       " 'train/recall': '0.9350 ± 0.0143',\n",
       " 'train_time': '17.9384 ± 1.8442'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_repeated_labse_single(name=\"labse_single_polish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1\n",
      "Global seed set to 2\n",
      "Global seed set to 3\n",
      "Global seed set to 4\n",
      "Global seed set to 5\n",
      "Global seed set to 6\n",
      "Global seed set to 7\n",
      "Global seed set to 8\n",
      "Global seed set to 9\n",
      "Global seed set to 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test/loss': '0.6740 ± 0.0334',\n",
       " 'test/f1': '0.6120 ± 0.0128',\n",
       " 'test/acc': '0.5952 ± 0.0358',\n",
       " 'test/precision': '0.5193 ± 0.0349',\n",
       " 'test/recall': '0.7614 ± 0.1021',\n",
       " 'train/loss': '0.6136 ± 0.0354',\n",
       " 'train/f1': '0.6276 ± 0.0347',\n",
       " 'train/acc': '0.6580 ± 0.0318',\n",
       " 'train/precision': '0.5812 ± 0.0333',\n",
       " 'train/recall': '0.6838 ± 0.0502',\n",
       " 'train_time': '8.4854 ± 0.4961'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_repeated_labse_single(\n",
    "    name=\"labse_single_english\",\n",
    "    train_path=ENGLISH_TRAIN,\n",
    "    test_path=ENGLISH_TEST,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1\n",
      "Global seed set to 2\n",
      "Global seed set to 3\n",
      "Global seed set to 4\n",
      "Global seed set to 5\n",
      "Global seed set to 6\n",
      "Global seed set to 7\n",
      "Global seed set to 8\n",
      "Global seed set to 9\n",
      "Global seed set to 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'english_test/loss': '0.6740 ± 0.0334',\n",
       " 'english_test/f1': '0.6120 ± 0.0128',\n",
       " 'english_test/acc': '0.5952 ± 0.0358',\n",
       " 'english_test/precision': '0.5193 ± 0.0349',\n",
       " 'english_test/recall': '0.7614 ± 0.1021',\n",
       " 'english_train/loss': '0.6136 ± 0.0354',\n",
       " 'english_train/f1': '0.6276 ± 0.0347',\n",
       " 'english_train/acc': '0.6580 ± 0.0318',\n",
       " 'english_train/precision': '0.5812 ± 0.0333',\n",
       " 'english_train/recall': '0.6838 ± 0.0502',\n",
       " 'polish_pre_training_test/loss': '0.5710 ± 0.0540',\n",
       " 'polish_pre_training_test/f1': '0.2984 ± 0.0284',\n",
       " 'polish_pre_training_test/acc': '0.7462 ± 0.0712',\n",
       " 'polish_pre_training_test/precision': '0.2598 ± 0.0468',\n",
       " 'polish_pre_training_test/recall': '0.4157 ± 0.1552',\n",
       " 'polish_test/loss': '0.3433 ± 0.0142',\n",
       " 'polish_test/f1': '0.4422 ± 0.0241',\n",
       " 'polish_test/acc': '0.8831 ± 0.0043',\n",
       " 'polish_test/precision': '0.6143 ± 0.0326',\n",
       " 'polish_test/recall': '0.3463 ± 0.0264',\n",
       " 'polish_train/loss': '0.1188 ± 0.0363',\n",
       " 'polish_train/f1': '0.9204 ± 0.0277',\n",
       " 'polish_train/acc': '0.9862 ± 0.0050',\n",
       " 'polish_train/precision': '0.9101 ± 0.0423',\n",
       " 'polish_train/recall': '0.9315 ± 0.0154'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_repeated_labse_multi(name=\"labse_multi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_model = SentenceTransformer(\"sentence-transformers/LaBSE\")\n",
    "get_embeddings = lambda x: embeddings_model.encode(\n",
    "    x,\n",
    "    convert_to_numpy=False,\n",
    "    convert_to_tensor=True,\n",
    "    batch_size=128,\n",
    ").cpu()\n",
    "\n",
    "dataset = TextDataset(PROBLEM_TEST, get_embeddings)\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=128,\n",
    "    pin_memory=True,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "checkpoint_file = CHECKPOINTS_DIR / \"labse_single_polish_1.ckpt\"\n",
    "model = BinaryMLP.load_from_checkpoint(\n",
    "    checkpoint_file,\n",
    "    emb_dim=768,\n",
    "    hidden_dims=[256, 128],\n",
    "    learning_rate=1e-4,\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.0003 ± 0.0001'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_inference_time(model, loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.883 MB'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_memory_usage(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted correctly: 893\n",
      "Predicted incorrectly: 107\n",
      "\n",
      "Non-hate tweets predicted as hate: 25\n",
      "Most misclassified examples:\n",
      "\tProb: 0.999 \tText: 'celny snajperski strzał w lewacką chołotę'\n",
      "\tProb: 0.994 \tText: 'z koszulki na dupie też jesteś dumny'\n",
      "\tProb: 0.994 \tText: 'rt wiek to okropny złodziej kiedy zaczynasz rozumieć na czym polega życie ono ścina cię z nóg i przygarbia ci plecy'\n",
      "\tProb: 0.926 \tText: 'wiek to okropny złodziej kiedy zaczynasz rozumieć na czym polega życie ono ścina cię z nóg i przygarbia ci plecy'\n",
      "\tProb: 0.902 \tText: 'zgolić stasiek tyś się na amerykana zrobił w tym telewizorze tak się ciebie stało'\n",
      "\tProb: 0.896 \tText: 'pisowska pajęczyna inwazja psychopolactwa a my trwamy i trwać będziemy'\n",
      "\tProb: 0.891 \tText: 'no i super wracaj do swojego cienkiego piwa do niczego innego się nie nadajesz'\n",
      "\tProb: 0.848 \tText: 'ale ty jesteś zrzęda nie szkoda życia na takie ciągłe narzekanie'\n",
      "\tProb: 0.821 \tText: 'to ta pani co ma roztrojenie jaźni'\n",
      "\tProb: 0.802 \tText: 'ten to już zupełnie odwiesił mózg na kołek chory mózg'\n",
      "\n",
      "Hate tweets predicted as non-hate: 82\n",
      "Most misclassified examples:\n",
      "\tProb: 0.012 \tText: 'za szczyt chyba za szczytowanie'\n",
      "\tProb: 0.013 \tText: 'jebac chuju lewusów nikt mi nie bronil ale to przesada'\n",
      "\tProb: 0.018 \tText: 'konserwator kuwety gegacz i przechył mózgowy za pieniądze robił loda w tokfm'\n",
      "\tProb: 0.020 \tText: 'ten pierwszy pójdzie na wojnę będzie nas bronił patriota nawet miski ryżu nie chce'\n",
      "\tProb: 0.020 \tText: 'podobno przed sejmem ustawili gilotynę mają obcinać ręce ubywatelom rp ręce które podnieśli na władzę'\n",
      "\tProb: 0.022 \tText: 'te szambo ktore mysli ze jest wallenrodem spuszczam jednym ruchem i polecam'\n",
      "\tProb: 0.022 \tText: 'rt chciałbyś aby tak było miernoto'\n",
      "\tProb: 0.025 \tText: 'gdzie jest to całe zakłamane lewackie skurwysynstwo no gdzie'\n",
      "\tProb: 0.027 \tText: 'złodziejstwo kurestwo patologia kompleksy brak pewności siebie'\n",
      "\tProb: 0.027 \tText: 'jezdzisz na wózku tramwaj uciał ci nogi'\n"
     ]
    }
   ],
   "source": [
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=128,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "check_errors(model, PROBLEM_TEST, loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted correctly: 685\n",
      "Predicted incorrectly: 315\n",
      "\n",
      "Non-hate tweets predicted as hate: 253\n",
      "Most misclassified examples:\n",
      "\tProb: 0.747 \tText: 'no o dobrze precz z dyktaturą kobiet'\n",
      "\tProb: 0.744 \tText: 'wojna to zło nie idźmy tą drogą'\n",
      "\tProb: 0.711 \tText: 'wieczna zdrada nie zdrada trzeba rozmawiać pierdolenie od rzeczy'\n",
      "\tProb: 0.708 \tText: 'to pani krysia jest twoją ojczyzną'\n",
      "\tProb: 0.704 \tText: 'dajcie mi już te prawo jazdy'\n",
      "\tProb: 0.701 \tText: 'mogłem mogłem mogłem coś zrobić zamiast ciągle walić konia'\n",
      "\tProb: 0.700 \tText: 'bardzo dobrze pani mówi pani małgosiu'\n",
      "\tProb: 0.697 \tText: 'ten góral to taki amerykański widze'\n",
      "\tProb: 0.694 \tText: 'koty robią dziwne rzeczy kiedy nie patrzymy'\n",
      "\tProb: 0.691 \tText: 'i weź tu zostań psem'\n",
      "\n",
      "Hate tweets predicted as non-hate: 62\n",
      "Most misclassified examples:\n",
      "\tProb: 0.285 \tText: 'jak widzę byłego premiera marcinkiewicza to zawsze myślę qrwa jak ktoś taki mógł być premierem taki skończony błazen'\n",
      "\tProb: 0.287 \tText: 'jezdzisz na wózku tramwaj uciał ci nogi'\n",
      "\tProb: 0.300 \tText: 'o czym będzie łgał jutro'\n",
      "\tProb: 0.301 \tText: 'i zaczęło się krycie pedofili w sutannach'\n",
      "\tProb: 0.322 \tText: 'zrzekł się polskiego obywatelstwa dla kariery pogratulować'\n",
      "\tProb: 0.331 \tText: 'adrian juda figurant wsi i lobby żydowskiego'\n",
      "\tProb: 0.345 \tText: 'z tego co wiem to wyłowiono jego ciało z jakieś wody'\n",
      "\tProb: 0.351 \tText: 'widać ludziom w sączu tak pasuje ja bym mu w gębę napluł'\n",
      "\tProb: 0.359 \tText: 'znowu łżesz jak co dzień'\n",
      "\tProb: 0.362 \tText: 'za szczyt chyba za szczytowanie'\n"
     ]
    }
   ],
   "source": [
    "checkpoint_file = CHECKPOINTS_DIR / \"labse_multi_1_english.ckpt\"\n",
    "model = BinaryMLP.load_from_checkpoint(\n",
    "    checkpoint_file,\n",
    "    emb_dim=768,\n",
    "    hidden_dims=[256, 128],\n",
    "    learning_rate=1e-4,\n",
    ").cuda()\n",
    "\n",
    "check_errors(model, PROBLEM_TEST, loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted correctly: 880\n",
      "Predicted incorrectly: 120\n",
      "\n",
      "Non-hate tweets predicted as hate: 34\n",
      "Most misclassified examples:\n",
      "\tProb: 1.000 \tText: 'celny snajperski strzał w lewacką chołotę'\n",
      "\tProb: 0.992 \tText: 'rt wiek to okropny złodziej kiedy zaczynasz rozumieć na czym polega życie ono ścina cię z nóg i przygarbia ci plecy'\n",
      "\tProb: 0.986 \tText: 'z koszulki na dupie też jesteś dumny'\n",
      "\tProb: 0.984 \tText: 'to ta pani co ma roztrojenie jaźni'\n",
      "\tProb: 0.909 \tText: 'rt polacy ratujmy polskę od zlodzieji po i lisa woljsdojcza'\n",
      "\tProb: 0.904 \tText: 'znając mentalność pis winny będzie ten kto widzi nie ten kto czyni'\n",
      "\tProb: 0.904 \tText: 'ale ty jesteś zrzęda nie szkoda życia na takie ciągłe narzekanie'\n",
      "\tProb: 0.887 \tText: 'ten to już zupełnie odwiesił mózg na kołek chory mózg'\n",
      "\tProb: 0.882 \tText: 'u dentysty pani z polski ygdfsy nie mówimy a to gdzie pani się tak opaliła ygxhzh ale prosiłem żeby nie mówić'\n",
      "\tProb: 0.858 \tText: 'rt wydano zakaz zajmowania się michałem tuskiem pięknie'\n",
      "\n",
      "Hate tweets predicted as non-hate: 86\n",
      "Most misclassified examples:\n",
      "\tProb: 0.005 \tText: 'zrzekł się polskiego obywatelstwa dla kariery pogratulować'\n",
      "\tProb: 0.008 \tText: 'za szczyt chyba za szczytowanie'\n",
      "\tProb: 0.011 \tText: 'podobno przed sejmem ustawili gilotynę mają obcinać ręce ubywatelom rp ręce które podnieśli na władzę'\n",
      "\tProb: 0.013 \tText: 'o czym ty bredzisz jak nic nie wiesz o sprawie to się po prostu nie odzywaj i nie rób z siebie durnia'\n",
      "\tProb: 0.015 \tText: 'na szczęście i jego partia znikną wkrótce ze sceny politycznej brawo'\n",
      "\tProb: 0.018 \tText: 'ten pierwszy pójdzie na wojnę będzie nas bronił patriota nawet miski ryżu nie chce'\n",
      "\tProb: 0.022 \tText: 'rt gdybyście byli u władzy spałowalibyście taki marsz'\n",
      "\tProb: 0.023 \tText: 'konserwator kuwety gegacz i przechył mózgowy za pieniądze robił loda w tokfm'\n",
      "\tProb: 0.027 \tText: 'pani się dobrze zastanowi co robicie też macie biura samochody domy dzieci wnuki itd tak tylko przypominam'\n",
      "\tProb: 0.028 \tText: 'powinieneś wrócić do szamba z którego wylazłeś'\n"
     ]
    }
   ],
   "source": [
    "checkpoint_file = CHECKPOINTS_DIR / \"labse_multi_1_polish.ckpt\"\n",
    "model = BinaryMLP.load_from_checkpoint(\n",
    "    checkpoint_file,\n",
    "    emb_dim=768,\n",
    "    hidden_dims=[256, 128],\n",
    "    learning_rate=1e-4,\n",
    ").cuda()\n",
    "\n",
    "check_errors(model, PROBLEM_TEST, loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
