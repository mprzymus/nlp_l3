{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from statistics import mean, stdev\n",
    "\n",
    "import fasttext\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from config import SG_CORPUS, SG_FULL, CHECKPOINTS_DIR, PROBLEM_TEST\n",
    "from data import HatefulTweets, WordDataset\n",
    "from experiment import (\n",
    "    run_repeated_cnn,\n",
    "    test_inference_time,\n",
    "    calculate_memory_usage,\n",
    "    check_errors,\n",
    ")\n",
    "from nn import CNNModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1\n",
      "Global seed set to 2\n",
      "Global seed set to 3\n",
      "Global seed set to 4\n",
      "Global seed set to 5\n",
      "Global seed set to 6\n",
      "Global seed set to 7\n",
      "Global seed set to 8\n",
      "Global seed set to 9\n",
      "Global seed set to 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test/loss': '0.3190 ± 0.0112',\n",
       " 'test/f1': '0.5002 ± 0.0287',\n",
       " 'test/acc': '0.8954 ± 0.0062',\n",
       " 'test/precision': '0.6982 ± 0.0521',\n",
       " 'test/recall': '0.3910 ± 0.0295',\n",
       " 'train/loss': '0.0782 ± 0.0295',\n",
       " 'train/f1': '0.9741 ± 0.0179',\n",
       " 'train/acc': '0.9955 ± 0.0032',\n",
       " 'train/precision': '0.9560 ± 0.0325',\n",
       " 'train/recall': '0.9934 ± 0.0037',\n",
       " 'train_time': '95.4654 ± 10.1520'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_repeated_cnn(SG_CORPUS, name=\"cnn_corpus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1\n",
      "Global seed set to 2\n",
      "Global seed set to 3\n",
      "Global seed set to 4\n",
      "Global seed set to 5\n",
      "Global seed set to 6\n",
      "Global seed set to 7\n",
      "Global seed set to 8\n",
      "Global seed set to 9\n",
      "Global seed set to 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test/loss': '0.3371 ± 0.0126',\n",
       " 'test/f1': '0.4822 ± 0.0288',\n",
       " 'test/acc': '0.8867 ± 0.0057',\n",
       " 'test/precision': '0.6225 ± 0.0372',\n",
       " 'test/recall': '0.3940 ± 0.0288',\n",
       " 'train/loss': '0.0883 ± 0.0235',\n",
       " 'train/f1': '0.9723 ± 0.0135',\n",
       " 'train/acc': '0.9952 ± 0.0024',\n",
       " 'train/precision': '0.9517 ± 0.0240',\n",
       " 'train/recall': '0.9940 ± 0.0028',\n",
       " 'train_time': '89.5961 ± 5.8525'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_repeated_cnn(SG_FULL, name=\"cnn_full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "embeddings_model = fasttext.load_model(str(SG_CORPUS))\n",
    "\n",
    "dataset = WordDataset(PROBLEM_TEST, embeddings_model.get_word_vector, 32)\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=128,\n",
    "    pin_memory=True,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "checkpoint_file = CHECKPOINTS_DIR / \"cnn_corpus_1.ckpt\"\n",
    "model = CNNModel.load_from_checkpoint(\n",
    "    checkpoint_file,\n",
    "    conv_kernels=[3, 4, 5],\n",
    "    conv_filter=100,\n",
    "    head_dim=300,\n",
    "    sentence_length=32,\n",
    "    learning_rate=1e-5,\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.0008 ± 0.0010'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_inference_time(model, loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.725 MB'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_memory_usage(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted correctly: 894\n",
      "Predicted incorrectly: 106\n",
      "\n",
      "Non-hate tweets predicted as hate: 30\n",
      "Most misclassified examples:\n",
      "\tProb: 1.000 \tText: 'celny snajperski strzał w lewacką chołotę'\n",
      "\tProb: 1.000 \tText: 'ten to już zupełnie odwiesił mózg na kołek chory mózg'\n",
      "\tProb: 0.998 \tText: 'jestem ukrainskim żydem z polskim obywatelstwem tnij może jedna ci starczy'\n",
      "\tProb: 0.994 \tText: 'trzeba być patriotą swojego miasta swojego regionu swojej ziemi prezes j w'\n",
      "\tProb: 0.994 \tText: 'rt trzeba być patriotą swojego miasta swojego regionu swojej ziemi prezes j w'\n",
      "\tProb: 0.967 \tText: 'polacy ratujmy polskę od zlodzieji po i lisa woljsdojcza'\n",
      "\tProb: 0.942 \tText: 'pis już się zbliża już puka do twych drzwipobiegnij go przywitać z radości serce drży'\n",
      "\tProb: 0.936 \tText: 'rt polacy ratujmy polskę od zlodzieji po i lisa woljsdojcza'\n",
      "\tProb: 0.907 \tText: '“ brzydka z makijażem brzydka bez makijażu brzydka rano brzydka wieczorem brzydka'\n",
      "\tProb: 0.899 \tText: 'droga pkamilko leczyć się leczyć póki czas'\n",
      "\n",
      "Hate tweets predicted as non-hate: 76\n",
      "Most misclassified examples:\n",
      "\tProb: 0.045 \tText: 'nie kłóć się jak nie chcesz mieć później problemów'\n",
      "\tProb: 0.054 \tText: 'za szczyt chyba za szczytowanie'\n",
      "\tProb: 0.055 \tText: 'jak spraw zgb dalej nie masz wjazdu jak proces królowa zalaci'\n",
      "\tProb: 0.066 \tText: 'półgłówek wieliński wymyślił sobie półautorytaryzm'\n",
      "\tProb: 0.084 \tText: 'te szambo ktore mysli ze jest wallenrodem spuszczam jednym ruchem i polecam'\n",
      "\tProb: 0.085 \tText: 'on jest na poziomie pierdolniętyzaawansowany więc nie dziwi nic'\n",
      "\tProb: 0.089 \tText: 'przecież to proste wystarczy nie kraść'\n",
      "\tProb: 0.096 \tText: 'w powietrzu sa środki chemiczne uważaj wygladasz na podatnego'\n",
      "\tProb: 0.102 \tText: 'ta mała pizda jest na baterie napędza pizdę'\n",
      "\tProb: 0.106 \tText: 'tej szmaty się nie komentuje'\n"
     ]
    }
   ],
   "source": [
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=128,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "check_errors(model, PROBLEM_TEST, loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
