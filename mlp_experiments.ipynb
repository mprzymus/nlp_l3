{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from functools import partial\n",
    "from statistics import mean, stdev\n",
    "\n",
    "import fasttext\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from config import SG_CORPUS, SG_FULL, CHECKPOINTS_DIR, PROBLEM_TEST\n",
    "from data import HatefulTweets, TextDataset\n",
    "from experiment import (\n",
    "    run_repeated_mlp,\n",
    "    test_inference_time,\n",
    "    calculate_memory_usage,\n",
    "    check_errors,\n",
    ")\n",
    "from nn import BinaryMLP\n",
    "from text_processing import get_fasttext_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1\n",
      "Global seed set to 2\n",
      "Global seed set to 3\n",
      "Global seed set to 4\n",
      "Global seed set to 5\n",
      "Global seed set to 6\n",
      "Global seed set to 7\n",
      "Global seed set to 8\n",
      "Global seed set to 9\n",
      "Global seed set to 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test/loss': '0.3520 ± 0.0164',\n",
       " 'test/f1': '0.5026 ± 0.0283',\n",
       " 'test/acc': '0.8948 ± 0.0058',\n",
       " 'test/precision': '0.6879 ± 0.0458',\n",
       " 'test/recall': '0.3970 ± 0.0292',\n",
       " 'train/loss': '0.1511 ± 0.0316',\n",
       " 'train/f1': '0.8504 ± 0.0278',\n",
       " 'train/acc': '0.9741 ± 0.0050',\n",
       " 'train/precision': '0.8369 ± 0.0359',\n",
       " 'train/recall': '0.8646 ± 0.0213',\n",
       " 'train_time': '23.5230 ± 2.0934'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_repeated_mlp(SG_CORPUS, name=\"mlp_corpus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1\n",
      "Global seed set to 2\n",
      "Global seed set to 3\n",
      "Global seed set to 4\n",
      "Global seed set to 5\n",
      "Global seed set to 6\n",
      "Global seed set to 7\n",
      "Global seed set to 8\n",
      "Global seed set to 9\n",
      "Global seed set to 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test/loss': '0.3528 ± 0.0139',\n",
       " 'test/f1': '0.4802 ± 0.0343',\n",
       " 'test/acc': '0.8893 ± 0.0058',\n",
       " 'test/precision': '0.6491 ± 0.0430',\n",
       " 'test/recall': '0.3828 ± 0.0400',\n",
       " 'train/loss': '0.1464 ± 0.0315',\n",
       " 'train/f1': '0.8536 ± 0.0268',\n",
       " 'train/acc': '0.9747 ± 0.0050',\n",
       " 'train/precision': '0.8413 ± 0.0394',\n",
       " 'train/recall': '0.8667 ± 0.0163',\n",
       " 'train_time': '24.0255 ± 2.2360'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_repeated_mlp(SG_FULL, name=\"mlp_full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "embeddings_model = fasttext.load_model(str(SG_CORPUS))\n",
    "get_embeddings = partial(get_fasttext_embeddings, embeddings_model)\n",
    "\n",
    "dataset = TextDataset(PROBLEM_TEST, get_embeddings)\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=128,\n",
    "    pin_memory=True,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "checkpoint_file = CHECKPOINTS_DIR / \"mlp_corpus_1.ckpt\"\n",
    "model = BinaryMLP.load_from_checkpoint(\n",
    "    checkpoint_file,\n",
    "    emb_dim=300,\n",
    "    hidden_dims=[512, 256, 128, 64],\n",
    "    learning_rate=1e-4,\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.0003 ± 0.0001'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_inference_time(model, loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.261 MB'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_memory_usage(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted correctly: 896\n",
      "Predicted incorrectly: 104\n",
      "\n",
      "Non-hate tweets predicted as hate: 26\n",
      "Most misclassified examples:\n",
      "\tProb: 1.000 \tText: 'celny snajperski strzał w lewacką chołotę'\n",
      "\tProb: 0.997 \tText: 'bo ty tam pracujesz oszołomie'\n",
      "\tProb: 0.974 \tText: 'wracaj szybko bo widzisz jak bez ciebie nam idzie'\n",
      "\tProb: 0.912 \tText: 'wieczna zdrada nie zdrada trzeba rozmawiać pierdolenie od rzeczy'\n",
      "\tProb: 0.902 \tText: 'droga pkamilko leczyć się leczyć póki czas'\n",
      "\tProb: 0.862 \tText: 'też jesteś kwiatem tylko że chwastem'\n",
      "\tProb: 0.822 \tText: 'rt panie kropiwnicki w latach 80 wojsko polskie skladalo przysięgę na wierność w szeregach armi radzieckiej'\n",
      "\tProb: 0.806 \tText: 'tomaszowi szkoda że pmm nie schował zarobionej kasy w lisiej norze'\n",
      "\tProb: 0.805 \tText: 'rt tomaszowi szkoda że pmm nie schował zarobionej kasy w lisiej norze'\n",
      "\tProb: 0.786 \tText: 'ten to już zupełnie odwiesił mózg na kołek chory mózg'\n",
      "\n",
      "Hate tweets predicted as non-hate: 78\n",
      "Most misclassified examples:\n",
      "\tProb: 0.039 \tText: 'zrzekł się polskiego obywatelstwa dla kariery pogratulować'\n",
      "\tProb: 0.042 \tText: 'ssą wszystkimi otworami co tylko da się wessać'\n",
      "\tProb: 0.044 \tText: 'i tym sposobem zwyciężczynią turnieju o plastusiowego debila została agnieszka holland brawo'\n",
      "\tProb: 0.045 \tText: 'rt powinnaś odpowiedzieć za działanie na szkodę polski i obywateli'\n",
      "\tProb: 0.047 \tText: 'powinnaś odpowiedzieć za działanie na szkodę polski i obywateli'\n",
      "\tProb: 0.050 \tText: 'o czym będzie łgał jutro'\n",
      "\tProb: 0.064 \tText: 'on jest na poziomie pierdolniętyzaawansowany więc nie dziwi nic'\n",
      "\tProb: 0.064 \tText: 'kama słuchej no gdzie masz biuro chciałbym coś machnąć sprajem'\n",
      "\tProb: 0.067 \tText: 'lis czy ty jesteś żydem'\n",
      "\tProb: 0.068 \tText: 'nie kłóć się jak nie chcesz mieć później problemów'\n"
     ]
    }
   ],
   "source": [
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=128,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "check_errors(model, PROBLEM_TEST, loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
